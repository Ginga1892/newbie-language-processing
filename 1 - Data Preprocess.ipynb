{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 写给自然语言处理小白——某NLP小白\n",
    "同样作为一个NLP的新手，本系列将给大家分享简单实用的NLP必备知识和Python使用技巧，助大家轻松入门~\n",
    "\n",
    "很快你将会学会如下操作，成为别人眼中的大佬。\n",
    "\n",
    "↓↓↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.function as F\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP初步：数据预处理\n",
    "本篇将介绍给大家NLP或数据科学工作当中的第一步，数据预处理，也就是如何读写你手头的数据，通常我们会见到的数据格式有`.json`/`.csv`/`.tsv`等。以下你将会学习：\n",
    "* csv\n",
    "* json\n",
    "* yaml\n",
    "* pandas\n",
    "* sqlite\n",
    "\n",
    "## csv/tsv\n",
    "csv/tsv是最常见的保存数据的格式，Kaggle上绝大部分数据集都是csv。而Python里带有csv的第三方库，用于读写csv类的文件。\n",
    "\n",
    "注意：csv也可以用pandas读，准确地说pandas啥都能读。。。但如果你只是单纯地想对行进行操作，pandas会麻烦那么一点，用csv就很简单粗暴，以下先介绍csv。\n",
    "\n",
    "**读取**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "file_name = 'csv_file0.csv'\n",
    "with open(file_name, 'r') as f:\n",
    "    file = csv.reader(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用csv对文件操作首先需要调用open打开文件，随后定义一个读的对象。\n",
    "\n",
    "这个类里的数据默认是按行进行存储的，因此接下来我们逐行来读取文件内容，也是最常用的操作。\n",
    "\n",
    "假设文件每行长成这样，我们想要读取每行的第二列：\n",
    "```csv\n",
    "natural language processing\n",
    "processing natural language\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file0 = 'csv_file0.csv'\n",
    "raw_data = []\n",
    "\n",
    "with open(csv_file0, 'r', encoding='utf-8') as f:\n",
    "    file = csv.reader(f)\n",
    "    for line in file:\n",
    "        raw_data.append(line[1])\n",
    "\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：encoding参数最好加上，不然默认会以gbk打开，很可能会是乱码。如果utf-8打开还是乱码的话可以使用utf-8-sig。\n",
    "\n",
    "**写入**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file1 = 'csv_file1.csv'\n",
    "line = [1, 2, 3]\n",
    "lines = [[1, 2, 3], [4, 5, 6]]\n",
    "\n",
    "with open(csv_file1, 'w', encoding='utf-8', newline='') as f:\n",
    "    file = csv.writer(f)\n",
    "#     file.writerow(line)\n",
    "    file.writerows(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "writerow接收一个一维数组，写入文件当前的一行，而writerows接收一个二维数组，会一次性写入多行。\n",
    "\n",
    "注意：这里newline参数没有的话，会默认写完一行空一行，也就是两行文字之间会隔一行。另外这里的encoding会保证之后用utf-8肯定能打得开。\n",
    "\n",
    "**tsv**\n",
    "\n",
    "接下来讲一下tsv，和csv很像，区别是它以\\t分隔，而csv以逗号分隔，因此只需要在csv的基础上指定一个分隔符参数即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_file0 = 'tsv_file0.tsv'\n",
    "raw_data = []\n",
    "\n",
    "with open(tsv_file0, 'r', encoding='utf-8') as f:\n",
    "    file = csv.reader(f, delimiter='\\t')\n",
    "    for line in file:\n",
    "        raw_data.append(line[1])\n",
    "\n",
    "tsv_file1 = 'tsv_file1.tsv'\n",
    "\n",
    "with open(tsv_file1, 'w', encoding='utf-8', newline='') as f:\n",
    "    file = csv.writer(f, delimiter='\\t')\n",
    "    file.writerows(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pandas\n",
    "pandas的话就比较强大了，兼容许多数据格式，但相应操作也比较复杂。pandas打开的文件数据在内部以DataFrame的方式存在，有点像关系型数据库，以下尽量避开高端操作。\n",
    "\n",
    "**读取csv/tsv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_data = pd.read_csv(csv_file0)\n",
    "for i in raw_data.index.values:\n",
    "    print(raw_data.iloc[i, 3])\n",
    "#     print(raw_data.loc[i, 'Age'])\n",
    "    \n",
    "raw_data = pd.read_csv(tsv_file0, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用pandas不需要事先调用open。\n",
    "\n",
    "调用iloc会定位到第i行j列，而loc会根据列的名称来定位，假设你的文件长这样：\n",
    "```csv\n",
    "Id Name Gender Age\n",
    "00 ginga male 20\n",
    "```\n",
    "那么上述两个写法的效果是一样。\n",
    "\n",
    "**写入csv/tsv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.to_csv(tsv_file1, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：调用to_xxx(file_name)时要保证xxx和file_name的格式一致。如果不想写入表头数据的话可以加header=0。\n",
    "\n",
    "**excel**\n",
    "\n",
    "有些时候数据是excel格式的，pandas也可以搞定，但需要安装依赖库xlrd。\n",
    "```bash\n",
    "conda install xlrd\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = 'excel_file.xlsx'\n",
    "\n",
    "raw_data = pd.read_excel(excel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## json/yaml\n",
    "json和yaml都是存储字典数据的常用格式，Python当中也有相应的第三方库。\n",
    "\n",
    "**json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_file0 = 'json_file0.json'\n",
    "json_file1 = 'json_file1.json'\n",
    "data = {'a': '欸', 'b': '笔', 'c': '吸'}\n",
    "\n",
    "with open(json_file0, 'r', encoding='utf-8') as f:\n",
    "    raw_data = json.load(f)\n",
    "    \n",
    "with open(json_file1, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：indent参数最好加，不然生成的json文件会长得很丑，如果你的数据有中文，需声明ensure_ascii=False，不然文件里只会显示ascii码。\n",
    "\n",
    "json除了上面的load和dump，你还会见到一种loads和dumps的用法，区别是前者接收的是文件对象，后者是字符串，所以要操作文件的话必须先read。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file0, 'r', encoding='utf-8') as f:\n",
    "    f_string = f.read()\n",
    "    raw_data = json.loads(f_string)\n",
    "\n",
    "with open(json_file1, 'w', encoding='utf-8') as f:\n",
    "    f_string = json.dumps(data, indent=4, ensure_ascii=False)\n",
    "    f.write(f_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**yaml**\n",
    "```bash\n",
    "pip install pyyaml\n",
    "```\n",
    "yaml与json的操作几乎一样，但yaml文件以缩进表示字典元素间的层级关系，-表示数组，并且文件里字符串不显示引号。\n",
    "```yaml\n",
    "name: ginga\n",
    "age: 20\n",
    "friends:\n",
    "  name: mary\n",
    "  age: 21\n",
    "hobby:\n",
    "  - sports\n",
    "  - coding\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "yaml_file0 = 'yaml_file0.yaml'\n",
    "yaml_file1 = 'yaml_file1.yaml'\n",
    "\n",
    "with open(yaml_file0, 'r', encoding='utf-8') as f:\n",
    "    raw_data = yaml.load(f)\n",
    "    \n",
    "with open(yaml_file1, 'w', encoding='utf-8') as f:\n",
    "    yaml.dump(data, f, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：要显示中文的话同样需要声明allow_unicode=True。\n",
    "## sqlite\n",
    "有些时候数据是以数据库的形式存在的，例如`.db`文件。这时候可以用嵌入在Python当中的sqlite3数据库来进行操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"test.db\")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "sql = 'SELECT * FROM Student WHERE age=20'\n",
    "cursor.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用sqlite有如下几步：\n",
    "* 建立数据库连接\n",
    "* 创建游标对象\n",
    "* 指定sql操作\n",
    "* 执行sql操作\n",
    "\n",
    "注意：如果sql语句中包含参数，需要将参数一起传入execute。\n",
    "\n",
    "接下来就是考验大家MySQL的本领了~\n",
    "\n",
    "以上就是第一期内容，相信你很快就能熟练运用Python处理数据了，剩下的就是跑模型了，换句话说你已经掌握了一半的NLP了！\n",
    "\n",
    "## <font color=red>下回：教你如何使用BERT</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
